{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Options:\n",
      "1. Collect Images\n",
      "2. Train Model\n",
      "3. Identify Faces\n",
      "4. Exit\n",
      "Invalid input.\n",
      "\n",
      "Options:\n",
      "1. Collect Images\n",
      "2. Train Model\n",
      "3. Identify Faces\n",
      "4. Exit\n",
      "Press 'q' to end capture.\n",
      "Collected 50 images for 1.\n",
      "\n",
      "Options:\n",
      "1. Collect Images\n",
      "2. Train Model\n",
      "3. Identify Faces\n",
      "4. Exit\n",
      "Model training complete.\n",
      "\n",
      "Options:\n",
      "1. Collect Images\n",
      "2. Train Model\n",
      "3. Identify Faces\n",
      "4. Exit\n",
      "Press 'q' to quit.\n",
      "Hello, 1!\n",
      "Hello, 1!\n",
      "Hello, 1!\n",
      "Hello, 1!\n",
      "Hello, 1!\n",
      "Hello, 1!\n",
      "Hello, 1!\n",
      "Hello, 1!\n",
      "Hello, 1!\n",
      "Hello, 1!\n",
      "Hello, 1!\n",
      "Hello, 1!\n",
      "Hello, 1!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "DIR = \"stored_faces\"\n",
    "MODEL_FILE = \"model.pkl\"\n",
    "NOTES_FILE = \"notes.json\"\n",
    "\n",
    "os.makedirs(DIR, exist_ok=True)\n",
    "if not os.path.exists(NOTES_FILE):\n",
    "    with open(NOTES_FILE, \"w\") as f:\n",
    "        json.dump({}, f)\n",
    "\n",
    "with open(NOTES_FILE, \"r\") as f:\n",
    "    notes = json.load(f)\n",
    "\n",
    "def sanitize(input_str):\n",
    "    return re.sub(r'[\\\\/*?:\"<>|]', \"_\", input_str)\n",
    "\n",
    "def collect_images():\n",
    "    person_name = input(\"Provide a name: \")\n",
    "    folder_name = sanitize(person_name)\n",
    "    path = os.path.join(DIR, folder_name)\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    capture = cv2.VideoCapture(0)\n",
    "    if not capture.isOpened():\n",
    "        print(\"Camera error.\")\n",
    "        return\n",
    "\n",
    "    print(\"Press 'q' to end capture.\")\n",
    "    img_count = 0\n",
    "\n",
    "    while True:\n",
    "        success, frame = capture.read()\n",
    "        if not success:\n",
    "            print(\"Frame error.\")\n",
    "            break\n",
    "\n",
    "        rgb_img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        detections = face_recognition.face_locations(rgb_img)\n",
    "\n",
    "        for (top, right, bottom, left) in detections:\n",
    "            img_count += 1\n",
    "            crop = frame[top:bottom, left:right]\n",
    "            cv2.imwrite(f\"{path}/{img_count}.jpg\", crop)\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "\n",
    "        cv2.imshow(\"Image Collection\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q') or img_count >= 50:\n",
    "            break\n",
    "\n",
    "    capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(f\"Collected {img_count} images for {folder_name}.\")\n",
    "\n",
    "def build_model():\n",
    "    encoded_faces = []\n",
    "    labels = []\n",
    "\n",
    "    for sub_dir in os.listdir(DIR):\n",
    "        person_path = os.path.join(DIR, sub_dir)\n",
    "        if not os.path.isdir(person_path):\n",
    "            continue\n",
    "\n",
    "        for img in os.listdir(person_path):\n",
    "            img_path = os.path.join(person_path, img)\n",
    "            try:\n",
    "                loaded_img = face_recognition.load_image_file(img_path)\n",
    "                encodings = face_recognition.face_encodings(loaded_img)\n",
    "                if encodings:\n",
    "                    encoded_faces.append(encodings[0])\n",
    "                    labels.append(sub_dir)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    with open(MODEL_FILE, \"wb\") as file:\n",
    "        pickle.dump({\"encodings\": encoded_faces, \"labels\": labels}, file)\n",
    "\n",
    "    print(\"Model training complete.\")\n",
    "\n",
    "def identify_faces():\n",
    "    if not os.path.exists(MODEL_FILE):\n",
    "        print(\"Model not found. Train the model first.\")\n",
    "        return\n",
    "\n",
    "    with open(MODEL_FILE, \"rb\") as file:\n",
    "        data = pickle.load(file)\n",
    "\n",
    "    saved_encodings = data[\"encodings\"]\n",
    "    saved_labels = data[\"labels\"]\n",
    "\n",
    "    capture = cv2.VideoCapture(0)\n",
    "    if not capture.isOpened():\n",
    "        print(\"Camera error.\")\n",
    "        return\n",
    "\n",
    "    print(\"Press 'q' to quit.\")\n",
    "    while True:\n",
    "        success, frame = capture.read()\n",
    "        if not success:\n",
    "            print(\"Frame error.\")\n",
    "            break\n",
    "\n",
    "        rgb_img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        detections = face_recognition.face_locations(rgb_img)\n",
    "        encodings = face_recognition.face_encodings(rgb_img, detections)\n",
    "\n",
    "        for (top, right, bottom, left), enc in zip(detections, encodings):\n",
    "            matches = face_recognition.compare_faces(saved_encodings, enc, tolerance=0.6)\n",
    "            label = \"Unknown\"\n",
    "\n",
    "            if True in matches:\n",
    "                closest = np.argmin(face_recognition.face_distance(saved_encodings, enc))\n",
    "                label = saved_labels[closest]\n",
    "\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, label, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "\n",
    "            if label != \"Unknown\":\n",
    "                print(f\"Hello, {label}!\")\n",
    "                if label not in notes or input(f\"Update note for {label}? (y/n): \").lower() == \"y\":\n",
    "                    note = input(f\"Add a note for {label}: \")\n",
    "                    notes[label] = note\n",
    "                    with open(NOTES_FILE, \"w\") as f:\n",
    "                        json.dump(notes, f)\n",
    "\n",
    "        cv2.imshow(\"Face Identification\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "while True:\n",
    "    print(\"\\nOptions:\")\n",
    "    print(\"1. Collect Images\")\n",
    "    print(\"2. Train Model\")\n",
    "    print(\"3. Identify Faces\")\n",
    "    print(\"4. Exit\")\n",
    "\n",
    "    selection = input(\"Choose an option: \")\n",
    "    if selection == \"1\":\n",
    "        collect_images()\n",
    "    elif selection == \"2\":\n",
    "        build_model()\n",
    "    elif selection == \"3\":\n",
    "        identify_faces()\n",
    "    elif selection == \"4\":\n",
    "        break\n",
    "    else:\n",
    "        print(\"Invalid input.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Options:\n",
      "1. Collect Images\n",
      "2. Train Model\n",
      "3. Identify Faces\n",
      "4. Exit\n",
      "Invalid input.\n",
      "\n",
      "Options:\n",
      "1. Collect Images\n",
      "2. Train Model\n",
      "3. Identify Faces\n",
      "4. Exit\n",
      "Press 'q' to end capture.\n",
      "Collected 50 images for 1.\n",
      "\n",
      "Options:\n",
      "1. Collect Images\n",
      "2. Train Model\n",
      "3. Identify Faces\n",
      "4. Exit\n",
      "Model training complete.\n",
      "\n",
      "Options:\n",
      "1. Collect Images\n",
      "2. Train Model\n",
      "3. Identify Faces\n",
      "4. Exit\n",
      "Press 'q' to quit.\n",
      "\n",
      "Options:\n",
      "1. Collect Images\n",
      "2. Train Model\n",
      "3. Identify Faces\n",
      "4. Exit\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "DIR = \"stored_faces\"\n",
    "MODEL_FILE = \"model.pkl\"\n",
    "NOTES_FILE = \"notes.json\"\n",
    "\n",
    "os.makedirs(DIR, exist_ok=True)\n",
    "if not os.path.exists(NOTES_FILE):\n",
    "    with open(NOTES_FILE, \"w\") as f:\n",
    "        json.dump({}, f)\n",
    "\n",
    "with open(NOTES_FILE, \"r\") as f:\n",
    "    notes = json.load(f)\n",
    "\n",
    "def sanitize(input_str):\n",
    "    return re.sub(r'[\\\\/*?:\"<>|]', \"_\", input_str)\n",
    "\n",
    "def collect_images():\n",
    "    person_name = input(\"Provide a name: \")\n",
    "    folder_name = sanitize(person_name)\n",
    "    path = os.path.join(DIR, folder_name)\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    capture = cv2.VideoCapture(0)\n",
    "    if not capture.isOpened():\n",
    "        print(\"Camera error.\")\n",
    "        return\n",
    "\n",
    "    print(\"Press 'q' to end capture.\")\n",
    "    img_count = 0\n",
    "\n",
    "    while True:\n",
    "        success, frame = capture.read()\n",
    "        if not success:\n",
    "            print(\"Frame error.\")\n",
    "            break\n",
    "\n",
    "        rgb_img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        detections = face_recognition.face_locations(rgb_img)\n",
    "\n",
    "        for (top, right, bottom, left) in detections:\n",
    "            img_count += 1\n",
    "            crop = frame[top:bottom, left:right]\n",
    "            cv2.imwrite(f\"{path}/{img_count}.jpg\", crop)\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "\n",
    "        cv2.imshow(\"Image Collection\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q') or img_count >= 50:\n",
    "            break\n",
    "\n",
    "    capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(f\"Collected {img_count} images for {folder_name}.\")\n",
    "\n",
    "def build_model():\n",
    "    encoded_faces = []\n",
    "    labels = []\n",
    "\n",
    "    for sub_dir in os.listdir(DIR):\n",
    "        person_path = os.path.join(DIR, sub_dir)\n",
    "        if not os.path.isdir(person_path):\n",
    "            continue\n",
    "\n",
    "        for img in os.listdir(person_path):\n",
    "            img_path = os.path.join(person_path, img)\n",
    "            try:\n",
    "                loaded_img = face_recognition.load_image_file(img_path)\n",
    "                encodings = face_recognition.face_encodings(loaded_img)\n",
    "                if encodings:\n",
    "                    encoded_faces.append(encodings[0])\n",
    "                    labels.append(sub_dir)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    with open(MODEL_FILE, \"wb\") as file:\n",
    "        pickle.dump({\"encodings\": encoded_faces, \"labels\": labels}, file)\n",
    "\n",
    "    print(\"Model training complete.\")\n",
    "\n",
    "def identify_faces():\n",
    "    if not os.path.exists(MODEL_FILE):\n",
    "        print(\"Model not found. Train the model first.\")\n",
    "        return\n",
    "\n",
    "    with open(MODEL_FILE, \"rb\") as file:\n",
    "        data = pickle.load(file)\n",
    "\n",
    "    saved_encodings = data[\"encodings\"]\n",
    "    saved_labels = data[\"labels\"]\n",
    "\n",
    "    capture = cv2.VideoCapture(0)\n",
    "    if not capture.isOpened():\n",
    "        print(\"Camera error.\")\n",
    "        return\n",
    "\n",
    "    print(\"Press 'q' to quit.\")\n",
    "    while True:\n",
    "        success, frame = capture.read()\n",
    "        if not success:\n",
    "            print(\"Frame error.\")\n",
    "            break\n",
    "\n",
    "        rgb_img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        detections = face_recognition.face_locations(rgb_img)\n",
    "        encodings = face_recognition.face_encodings(rgb_img, detections)\n",
    "\n",
    "        for (top, right, bottom, left), enc in zip(detections, encodings):\n",
    "            matches = face_recognition.compare_faces(saved_encodings, enc, tolerance=0.6)\n",
    "            label = \"Unknown\"\n",
    "\n",
    "            if True in matches:\n",
    "                closest = np.argmin(face_recognition.face_distance(saved_encodings, enc))\n",
    "                label = saved_labels[closest]\n",
    "\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, label, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "\n",
    "            if label != \"Unknown\" and label not in notes:\n",
    "                print(f\"Hello, {label}!\")\n",
    "                note = input(f\"Add a note for {label}: \")\n",
    "                notes[label] = note\n",
    "                with open(NOTES_FILE, \"w\") as f:\n",
    "                    json.dump(notes, f)\n",
    "\n",
    "        cv2.imshow(\"Face Identification\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "while True:\n",
    "    print(\"\\nOptions:\")\n",
    "    print(\"1. Collect Images\")\n",
    "    print(\"2. Train Model\")\n",
    "    print(\"3. Identify Faces\")\n",
    "    print(\"4. Exit\")\n",
    "\n",
    "    selection = input(\"Choose an option: \")\n",
    "    if selection == \"1\":\n",
    "        collect_images()\n",
    "    elif selection == \"2\":\n",
    "        build_model()\n",
    "    elif selection == \"3\":\n",
    "        identify_faces()\n",
    "    elif selection == \"4\":\n",
    "        break\n",
    "    else:\n",
    "        print(\"Invalid input.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
